
pip install numpy==1.26.4

import numpy as np
print(np.__version__)

!pip install Sweetviz

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from IPython import get_ipython
from IPython.display import display

data = pd.read_csv('/content/WBC data.csv')

data.head()

print("The unique number of data values are")
df = data
df.nunique()

data = pd.read_csv('/content/WBC data.csv')
df = data.copy()  # Create a copy to avoid modifying the original 'data'

df["diagnosis"].value_counts()
# Convert 'diagnosis' column to numerical values before calculating the mean
df['diagnosis'] = df['diagnosis'].map({'M': 1, 'B': 0})
print(df["diagnosis"].mean())
#Plot the number of data points with mailgnant and benign as their diagnosis
print("Total number of data points =  ", len(df))
print("Malignant (diagnosis =1) = {}%".format(round(df["diagnosis"].mean(),3)*100))

print("Benign (diagnosis =0)= {}%".format((1-round(df["diagnosis"].mean(),3))*100))
df.groupby("diagnosis")['id'].count().plot.bar(ylabel = "Number of data points", title = "Malignant (1) vs Benign Data(0) points", color = 'cyan', edgecolor = "royalblue")

from IPython.display import display, HTML, IFrame
import pandas as pd
import sweetviz as sv

# Load your dataset
data = pd.read_csv("/content/WBC data.csv")

# Analyze the dataset
sweetviz_report = sv.analyze(data)

# Save report to HTML
sweetviz_report.show_html("report.html")

# Display inside Colab (iframe)
display(IFrame(src='report.html', width=1000, height=600))

from google.colab import files
files.download('report.html')

""".

# **BOX PLOT**
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

data = pd.read_csv('/content/WBC data.csv')

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler # Import StandardScaler

# Load dataset
file_path = "/content/WBC data.csv"  # Adjust the path if needed
df = pd.read_csv(file_path)

# Drop non-feature columns (like ID or unnamed columns)
df = df.loc[:, ~df.columns.str.contains('Unnamed|id', case=False)]  # Remove ID/Unnamed columns if present

# Normalize data using StandardScaler
scaler = StandardScaler()
df_scaled = pd.DataFrame(scaler.fit_transform(df.select_dtypes(include=["number"])), columns=df.select_dtypes(include=["number"]).columns)

# Plot improved box plot
plt.figure(figsize=(15, 8))
sns.boxplot(data=df_scaled)
plt.xticks(rotation=90)
plt.title("Improved Box Plot of All Features in the Wisconsin Breast Cancer Dataset (Standardized)")
plt.show()

# Load dataset (update file path if needed)
file_path = '/content/WBC data.csv'
df = pd.read_csv(file_path)  # Load data again to ensure df is a DataFrame

# Remove unnecessary columns
df = df.drop(columns=['id', 'Unnamed: 32'], errors='ignore')

# Check if 'diagnosis' column exists
if 'diagnosis' in df.columns:
    df['diagnosis'] = df['diagnosis'].map({'M': 'Malignant', 'B': 'Benign'})
else:
    raise KeyError("Column 'diagnosis' not found in the dataset. Check column names:", df.columns)

# Select Important Features (Based on Feature Selection)
important_features = [
   'perimeter_mean', 'area_mean', 'concavity_mean', 'concave points_mean',
       'radius_worst', 'texture_worst', 'perimeter_worst', 'area_worst',
       'concavity_worst', 'concave points_worst'
]  # Modify this list based on your feature selection

# Keep only selected features + diagnosis
df_selected = df[['diagnosis'] + important_features]

# Melt dataset for Seaborn box plot
data_melted = df_selected.melt(id_vars=['diagnosis'], var_name='Feature', value_name='Value')

# Set style
sns.set(style="whitegrid")

# FacetGrid for multiple box plots
g = sns.FacetGrid(data_melted, col='Feature', hue='diagnosis', col_wrap=4, height=4, sharey=False , palette='Set2')
g.map_dataframe(sns.boxplot, x='diagnosis', y='Value', order=['Malignant', 'Benign'], showfliers=True)

# Set titles and labels
g.set_titles(col_template="{col_name}")
g.set_axis_labels("Diagnosis", "Feature Value")
g.add_legend(title='Diagnosis')

# Adjust layout and show plot
plt.subplots_adjust(top=0.9)
g.fig.suptitle('Box Plots of Important Wisconsin Breast Cancer Features', fontsize=16)
plt.show()

""".

# **SCATTER PLOT**
"""

# Load the dataset again, ensuring we're working with a DataFrame
file_path = '/content/WBC data.csv'
df = pd.read_csv(file_path)

# Select relevant features for the pair plot
features = ['perimeter_mean', 'area_mean', 'concavity_mean', 'concave points_mean',
       'radius_worst', 'texture_worst', 'perimeter_worst', 'area_worst',
       'concavity_worst', 'concave points_worst']

# Create a pair plot
sns.set(style="whitegrid")
pair_plot = sns.pairplot(df[features + ['diagnosis']], hue='diagnosis', palette={'M': 'red', 'B': 'blue'},
                         markers=['o', 's'], diag_kind='kde', height=3.0)

# Add titles and adjust layout
pair_plot.fig.suptitle('Pair Plot of Breast Cancer Features by Diagnosis', fontsize=20, y=1.12)

# Show the plot
plt.show()

""".

# **HEAT MAP**
"""

correlation_matrix = data[features].corr()

# Load dataset (update file path if needed)
file_path = '/content/WBC data.csv'
df = pd.read_csv(file_path)

# Drop unnecessary columns
df = df.loc[:, ~df.columns.str.contains('Unnamed', case=False)]
df = df.drop(columns=['id'], errors='ignore')

# Select only numeric columns for correlation calculation
numeric_df = df.select_dtypes(include=['float64', 'int64']).copy()

plt.figure(figsize =(30,30))
sns.heatmap(numeric_df.corr(), vmin=-1, vmax=1, annot=True)
plt.show()

# Load the dataset
df = pd.read_csv("/content/WBC data.csv")

# Drop any unnamed columns (like an index column)
df = df.loc[:, ~df.columns.str.contains('^Unnamed')]

# Drop ID column if it exists
if "id" in df.columns:
    df.drop(columns=["id"], inplace=True)

# Select only the specified features
selected_features = [
    'perimeter_mean', 'area_mean', 'concavity_mean', 'concave points_mean',
    'radius_worst', 'texture_worst', 'perimeter_worst', 'area_worst',
    'concavity_worst', 'concave points_worst'
]

# Ensure all selected features exist in the dataset
df_selected = df[selected_features]

# Compute correlation matrix
correlation_matrix = df_selected.corr()

# Plot heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm", fmt=".2f", linewidths=0.5)

# Title and display
plt.title("Heatmap of Selected Features in Wisconsin Dataset")
plt.show()

""".

# **LAZY CLASSIFICATION**
"""

!pip install lazypredict

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from lazypredict.Supervised import LazyClassifier
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from google.colab import files

# Load your dataset
df = pd.read_csv('/content/WBC data.csv')  # Assuming your dataset is named 'data.csv'

# Assuming 'diagnosis' is your target variable
X = df.drop(columns=['diagnosis', 'id', 'Unnamed: 32'])  # Drop non-numeric columns
y = df['diagnosis']

# Preprocessing to handle potential issues in the dataset
X.replace([np.inf, -np.inf], np.nan, inplace=True)  # Replace infinite values with NaN
X.fillna(X.mean(), inplace=True)  # Impute NaN values with the mean
y = y.reindex(X.index)  # Reset index of y to match X

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Handling extreme values (e.g., clipping)
X_train = np.clip(X_train, -10, 10)  # Clip values to the range [-10, 10]
X_test = np.clip(X_test, -10, 10)

# Changing data type to numpy.float64
X_train = X_train.astype(np.float64)
X_test = X_test.astype(np.float64)

# Scale the features
scaler = StandardScaler()

# Calculate variances and filter features
variances = X_train.var()
# Set a threshold for minimum variance
min_variance = 1e-6  # Adjust this value as needed
# Select features with variance above the threshold
features_to_keep = variances[variances > min_variance].index
X_train = X_train[features_to_keep]
X_test = X_test[features_to_keep]

X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Initialize LazyClassifier
clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)

# Train and evaluate models
models, predictions = clf.fit(X_train, X_test, y_train, y_test)

# Get top 4 models
top_models = models.sort_values(by='Accuracy', ascending=False).head(4)
print("\nTop 4 Models Based on Accuracy:")
print(top_models)

for model_name in top_models.index.tolist():
    print(f"\nTraining and Evaluating Model: {model_name}")
    # Get the actual model instead of the ColumnTransformer
    model = clf.models[model_name][1]  # Access the model, not the transformer
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    # Evaluate the model
    accuracy = accuracy_score(y_test, y_pred)
    conf_matrix = confusion_matrix(y_test, y_pred)
    class_report = classification_report(y_test, y_pred)

    # Display results
    print(f"\nAccuracy of {model_name}: {accuracy}")
    print("\nConfusion Matrix:")
    print(conf_matrix)
    print("\nClassification Report:")
    print(class_report)

    # Visualize confusion matrix
    plt.figure(figsize=(8, 6))
    sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues",
                xticklabels=['Benign (B)', 'Malignant (M)'],
                yticklabels=['Benign (B)', 'Malignant (M)'])
    plt.xlabel("Predicted Label")
    plt.ylabel("True Label")
    plt.title(f"Confusion Matrix for {model_name}")
    plt.show()

""".

.

# **Classification threshold tuning**
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
import matplotlib.pyplot as plt

# ===== Load your dataset =====
data = pd.read_csv('/content/WBC data.csv')

# Select features and target
X = data.drop(columns=['diagnosis', 'id', 'Unnamed: 32'], errors='ignore') # Drop target, id, and the empty column
y = data['diagnosis']    # Select the diagnosis column as the target

# ===== Encode target labels (e.g., B=0, M=1) =====
le = LabelEncoder()
y = le.fit_transform(y)

# ===== Split dataset =====
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# ===== Feature scaling =====
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

from sklearn.linear_model import SGDClassifier
from sklearn.calibration import CalibratedClassifierCV

# Base SGD Classifier
base_clf = SGDClassifier(loss="hinge", random_state=42, max_iter=10000)

# Wrap with CalibratedClassifierCV to get probability estimates
clf = CalibratedClassifierCV(base_clf, cv=5)
clf.fit(X_train, y_train)

# Get probability predictions (values between 0 and 1)
y_proba = clf.predict_proba(X_test)[:, 1]

# ===== Predict probabilities =====
y_proba = clf.predict_proba(X_test)[:, 1]  # Probabilities for positive class

# ===== Threshold tuning =====
thresholds = np.arange(0.0, 1.01, 0.01)
results = []

for t in thresholds:
    y_pred = (y_proba >= t).astype(int)
    acc = accuracy_score(y_test, y_pred)
    prec = precision_score(y_test, y_pred, zero_division=0)
    rec = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    results.append([t, acc, prec, rec, f1])

# Convert to DataFrame
results_df = pd.DataFrame(results, columns=["Threshold", "Accuracy", "Precision", "Recall", "F1"])

# ===== Show all thresholds =====
pd.set_option("display.max_rows", None)
print(results_df)

# ===== Find best threshold for each metric =====
best_accuracy = results_df.loc[results_df["Accuracy"].idxmax()]
best_precision = results_df.loc[results_df["Precision"].idxmax()]
best_recall = results_df.loc[results_df["Recall"].idxmax()]
best_f1 = results_df.loc[results_df["F1"].idxmax()]

print("\nBest Accuracy:\n", best_accuracy)
print("\nBest Precision:\n", best_precision)
print("\nBest Recall:\n", best_recall)
print("\nBest F1-score:\n", best_f1)

# ===== ROC-AUC (independent of threshold) =====
auc = roc_auc_score(y_test, y_proba)
print(f"\nROC-AUC Score: {auc:.4f}")

# ===== Plot metrics vs threshold =====
plt.figure(figsize=(10,6))
plt.plot(results_df["Threshold"], results_df["Accuracy"], label="Accuracy")
plt.plot(results_df["Threshold"], results_df["Precision"], label="Precision")
plt.plot(results_df["Threshold"], results_df["Recall"], label="Recall")
plt.plot(results_df["Threshold"], results_df["F1"], label="F1-score")

# === Add vertical lines at best thresholds ===
plt.axvline(best_accuracy["Threshold"], color="blue", linestyle="--", alpha=0.7,
            label=f"Best Accuracy ({best_accuracy['Threshold']:.2f})")
plt.axvline(best_precision["Threshold"], color="orange", linestyle="--", alpha=0.7,
            label=f"Best Precision ({best_precision['Threshold']:.2f})")
plt.axvline(best_recall["Threshold"], color="green", linestyle="--", alpha=0.7,
            label=f"Best Recall ({best_recall['Threshold']:.2f})")
plt.axvline(best_f1["Threshold"], color="red", linestyle="--", alpha=0.7,
            label=f"Best F1 ({best_f1['Threshold']:.2f})")

plt.xlabel("Threshold")
plt.ylabel("Score")
plt.title("Model Performance Across Thresholds")
plt.legend()
plt.grid(True)
plt.show()

